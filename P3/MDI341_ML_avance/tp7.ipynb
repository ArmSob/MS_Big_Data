{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Large Scale Kernel Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_svmlight_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement et partitionnement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Requires file ijcnn1.dat.gz to be present in the directory\n",
    "\n",
    "dataset_path = 'ijcnn1.dat.gz'\n",
    "ijcnn1 = load_svmlight_file(dataset_path)\n",
    "X = ijcnn1[0].todense()\n",
    "y = ijcnn1[1]\n",
    "\n",
    "###############################################################################\n",
    "# Extract features\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:60000, :], y[:60000],\n",
    "                     train_size=20000, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "n1, p = X_train.shape\n",
    "n2 = X_test.shape[0]\n",
    "\n",
    "print(\"Nombre d'exemples d'apprentissage:\", n1)\n",
    "print(\"Nombre d'exemples de test:\", n2)\n",
    "print(\"Nombre de features:\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va fitter nos données d'apprentissage avec un SVM linéaire et un SVM non-linéaire (noyau Gaussien) pour comparer leur score de prédiction ainsi que le temps de calcul nécessaire à l'apprentissage et à la prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from time import time\n",
    "\n",
    "print(\"Fitting SVC rbf on %d samples...\" % X_train.shape[0])\n",
    "t0 = time()\n",
    "# TODO\n",
    "# clf = \n",
    "# clf.fit\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(\"Predicting with SVC rbf on %d samples...\" % X_test.shape[0])\n",
    "t1 = time()\n",
    "# TODO\n",
    "print(\"done in %0.3fs\" % (time() - t1))\n",
    "timing_kernel = time() - t0\n",
    "print(\"classification accuracy: %0.3f\" % accuracy_kernel)\n",
    "\n",
    "# TODO same for LinearSVC\n",
    "\n",
    "# timing_linear = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On code une fonction qui calcule la meilleure approximation de rang $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "from scipy.linalg import svd\n",
    "\n",
    "def rank_trunc(gram_mat, k, fast=True):\n",
    "    \"\"\"\n",
    "    k-th order approximation of the Gram Matrix G.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gram_mat : array, shape (n_samples, n_samples)\n",
    "        the Gram matrix\n",
    "    k : int\n",
    "        the order approximation\n",
    "    fast : bool\n",
    "        use svd (if False) or svds (if True).\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    gram_mat_k : array, shape (n_samples, n_samples)\n",
    "        The rank k Gram matrix.\n",
    "    \"\"\"\n",
    "    if fast:\n",
    "        pass  # TODO\n",
    "    else:\n",
    "        pass  # TODO\n",
    "\n",
    "    return gram_mat_k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On applique cette fonction sur la matrice décrite dans le sujet de TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 200\n",
    "r_noise = 100\n",
    "r_signal = 20\n",
    "\n",
    "intensity = 50\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "X_noise = rng.randn(r_noise, p)\n",
    "X_signal = rng.randn(r_signal, p)\n",
    "\n",
    "gram_signal = np.dot(X_noise.T, X_noise) + intensity * np.dot(X_signal.T,\n",
    "                                                              X_signal)\n",
    "n_ranks = 100\n",
    "ranks = np.arange(1, n_ranks + 1)\n",
    "timing_fast = np.zeros(n_ranks)\n",
    "timing_slow = np.zeros(n_ranks)\n",
    "rel_error = np.zeros(n_ranks)\n",
    "\n",
    "for k, rank in enumerate(ranks):\n",
    "    print(k, rank)\n",
    "    t0 = time()\n",
    "    gram_mat_k = rank_trunc(gram_signal, rank, fast=True)\n",
    "    timing_fast[k] = time() - t0\n",
    "\n",
    "    t0 = time()\n",
    "    gram_mat_k = rank_trunc(gram_signal, rank, fast=False)\n",
    "    timing_slow[k] = time() - t0\n",
    "\n",
    "    # TODO: compute relative error with Frobenius norm\n",
    "    rel_error[k] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Display\n",
    "\n",
    "f, axes = plt.subplots(ncols=1, nrows=2, figsize=(10,6))\n",
    "ax1, ax2 = axes.ravel()\n",
    "\n",
    "ax1.plot(ranks, timing_fast, '-', label='fast')\n",
    "ax1.plot(ranks, timing_slow, '-', label='slow')\n",
    "ax1.legend()\n",
    "\n",
    "ax1.set_xlabel('Rank')\n",
    "ax1.set_ylabel('Time')\n",
    "ax2.plot(ranks, rel_error, '-')\n",
    "ax2.set_xlabel('Rank')\n",
    "ax2.set_ylabel('Relative Error')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va implémenter l'algorithme de Random Kernel Features pour le noyau Gaussien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_features(X_train, X_test, gamma, c=300, seed=44):\n",
    "    \"\"\"Compute random kernel features\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : array, shape (n_samples1, n_features)\n",
    "        The train samples.\n",
    "    X_test : array, shape (n_samples2, n_features)\n",
    "        The test samples.\n",
    "    gamma : float\n",
    "        The Gaussian kernel parameter\n",
    "    c : int\n",
    "        The number of components\n",
    "    seed : int\n",
    "        The seed for random number generation\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    X_new_train : array, shape (n_samples1, c)\n",
    "        The new train samples.\n",
    "    X_new_test : array, shape (n_samples2, c)\n",
    "        The new test samples.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    n_samples, n_features = X_train.shape\n",
    "    \n",
    "    # TODO\n",
    "    \n",
    "    return X_new_train, X_new_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant appliquer cette méthode avec $c=300$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples, n_features = X_train.shape\n",
    "n_samples_test, _ = X_test.shape\n",
    "gamma = 1. / n_features\n",
    "\n",
    "Z_train, Z_test = random_features(X_train, X_test, gamma, c=300, seed=44)\n",
    "\n",
    "print(\"Fitting SVC linear on %d samples...\" % n_samples)\n",
    "t0 = time()\n",
    "clf = LinearSVC(dual=False)\n",
    "clf.fit(Z_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(\"Predicting with SVC linear on %d samples...\" % n_samples_test)\n",
    "t0 = time()\n",
    "accuracy = clf.score(Z_test, y_test)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"classification accuracy: %0.3f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On implémente la méthode de Nystrom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "def nystrom(X_train, X_test, gamma, c=500, k=200, seed=44):\n",
    "    \"\"\"Compute nystrom kernel approximation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : array, shape (n_samples1, n_features)\n",
    "        The train samples.\n",
    "    X_test : array, shape (n_samples2, n_features)\n",
    "        The test samples.\n",
    "    gamma : float\n",
    "        The Gaussian kernel parameter\n",
    "    c : int\n",
    "        The number of points to sample for the approximation\n",
    "    k : int\n",
    "        The number of components\n",
    "    seed : int\n",
    "        The seed for random number generation\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    X_new_train : array, shape (n_samples1, c)\n",
    "        The new train samples.\n",
    "    X_new_test : array, shape (n_samples2, c)\n",
    "        The new test samples.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    n_samples = X_train.shape[0]\n",
    "    idx = rng.choice(n_samples, c)\n",
    "\n",
    "    X_train_idx = X_train[idx, :]\n",
    "    W = rbf_kernel(X_train_idx, X_train_idx, gamma=gamma)\n",
    "    \n",
    "    # TODO\n",
    "\n",
    "    return X_new_train, X_new_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant appliquer cette méthode également avec $c=500$ et $k=300$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z_train, Z_test = nystrom(X_train, X_test, gamma, c=500, k=300, seed=44)\n",
    "\n",
    "print(\"Fitting SVC linear on %d samples...\" % n_samples)\n",
    "t0 = time()\n",
    "clf = LinearSVC(dual=False)\n",
    "clf.fit(Z_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(\"Predicting with SVC linear on %d samples...\" % n_samples_test)\n",
    "t0 = time()\n",
    "accuracy = clf.score(Z_test, y_test)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"classification accuracy: %0.3f\" % accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant réaliser une synthèse des performances des RKF et de Nystrom pour un ensemble de paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranks = np.arange(20, 600, 50)\n",
    "n_ranks = len(ranks)\n",
    "timing_rkf = np.zeros(n_ranks)\n",
    "timing_nystrom = np.zeros(n_ranks)\n",
    "\n",
    "accuracy_nystrom = np.zeros(n_ranks)\n",
    "accuracy_rkf = np.zeros(n_ranks)\n",
    "\n",
    "print(\"Training SVMs for various values of c...\")\n",
    "\n",
    "for i, c in enumerate(ranks):\n",
    "    print(i, c)\n",
    "    # TODO: compute time and prediction scores for RKF and Nystrom with respect to c\n",
    "    # put results in timing_rkf, timing_nystrom, accuracy_rkf, accuracy_nystrom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Display bis\n",
    "\n",
    "f, axes = plt.subplots(ncols=1, nrows=2, figsize=(10,6))\n",
    "ax1, ax2 = axes.ravel()\n",
    "\n",
    "ax1.plot(ranks-10, timing_nystrom, '-', label='Nystrom')\n",
    "ax1.plot(ranks, timing_rkf, '-', label='RKF')\n",
    "ax1.plot(ranks, timing_linear * np.ones(n_ranks), '-', label='LinearSVC')\n",
    "ax1.plot(ranks, timing_kernel * np.ones(n_ranks), '-', label='RBF')\n",
    "\n",
    "ax1.set_xlabel('Number of features')\n",
    "ax1.set_ylabel('Time')\n",
    "ax1.legend(loc='lower right')\n",
    "\n",
    "ax2.plot(ranks-10, accuracy_nystrom, '-', label='Nystrom')\n",
    "ax2.plot(ranks, accuracy_rkf, '-', label='RKF')\n",
    "ax2.plot(ranks, accuracy_linear * np.ones(n_ranks), '-', label='LinearSVC')\n",
    "ax2.plot(ranks, accuracy_kernel * np.ones(n_ranks), '-', label='RBF')\n",
    "ax2.set_xlabel('Number of features')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
