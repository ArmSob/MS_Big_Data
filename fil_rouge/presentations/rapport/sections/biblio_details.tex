\section{Research paper summaries}
\label{sec5}


The aim of this section to provide a summary of the research papers we include in the bibliography. What I propose is that for each paper we add in the bibliography, we include here a very short (2-3 lines maximum) summary of the paper. This creates a library of all the relevant papers. It may sound tedious, but this way we can help each other save a lot of time by just reading a few lines for each paper, gathered in a single section. 


Just an example of what I suggest:


\textbf{\cite{Carter2019}:}

Carter, Shan and Armstrong, Zan and Schubert, Ludwig and Johnson, Ian and Olah, Chris

``Exploring Neural Networks with Activation Atlases''\\
Summary: a paper that introduces activation atlases, a method to visualise how the network as a whole represents concepts through averaged activations.
 


\textbf{\cite{Hinton2006}:}

Hinton, G. E. and Salakhutdinov, R. R.

``Reducing the Dimensionality of Data with Neural Networks''\\
Summary: the paper that reinvigarated research in deep learning, laying the foundations of training for deep learning models. Uses the concept of pretraining.
 


\textbf{\cite{Rosenblatt1958}:}

Rosenblatt, Frank

``The perceptron: a probabilistic model for information storage and organization in the brain''\\
Summary: the first paper to develop the concept of perceptron.
 


\textbf{\cite{Rumelhart1986}:}

Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.

``Learning representations by back-propagating errors''\\
Summary: an early paper on multi-layer perceptrons, and the first paper to develop estimation by back-propagation.
 


\textbf{\cite{Widrow1960}:}

Widrow, B. and Hoff, M. E.

``Adaptative switching circuits''\\
Summary: an early paper on neural networks, with Adaline/Madaline methodology.
 


\textbf{\cite{Fukushima1980}:}

Fukushima, Kunihiko

``Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position''\\
Summary: first paper to adopt a convolutional-like neural network (named a ``sandwich architecture'').
 


\textbf{\cite{LeCun1989}:}

LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. andHoward, R. E. and Hubbard, W. and Jackel, L. D.

``Backpropagation Applied to Zip Code Recognition''\\
Summary: first deep convolution network.


\pagebreak

\textbf{\cite{LeCun1998}:}

LeCun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.

``Gradient-based learning applied to document recognition''\\
Summary: gradient learning methods to train deep convolution network. Introduction of CNN LeNet-5.



\textbf{\cite{Seide2011}:}

Seide, Frank and Li, Gang and Yu, Dong

``Conversational Speech Transcription Using Context-Dependent Deep Neural Networks''\\
Summary: revival of deep learning: field of speech recognition.



\textbf{\cite{Krizhevsky2012}:}

Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.

``ImageNet Classification with Deep Convolutional Neural Networks''\\
Summary: revival of deep learning: field of image classification.



\textbf{\cite{Szegedy2015}:}

Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew

``Rethinking the Inception Architecture for Computer Vision''\\
Summary: ConvNets are everywhere: recent application in computer vision.



\textbf{\cite{Levy2016}:}

Lévy, Daniel and Jain, Arzay

``Breast Mass Classification from Mammograms using Deep Convolutional Neural Networks''\\
Summary: ConvNets are everywhere: recent application in medical research.



\textbf{\cite{Dieleman2014}:}

Dieleman, Sander and Willett, Kyle W. and Dambre, Joni

``Rotation-invariant convolutional neural networks for galaxy morphology prediction''\\
Summary: ConvNets are everywhere: recent application in astronomy.



\textbf{\cite{Karpathy2015}:} 

Karpathy, Andrej and Fei-Fei, Li

``Deep Visual-Semantic Alignments for Generating Image Descriptions''\\
Summary: ConvNets are everywhere: recent application in image captioning.



\textbf{\cite{Gatys2016}:} 

Gatys, L. A. and Ecker, A. S. and Bethge, M.

``Image Style Transfer Using Convolutional Neural Networks''\\
Summary: ConvNets are everywhere: recent application in art.




\textbf{\cite{Shrikumar2017}:} 

Shrikumar Avanti, Greenside Peyton, Kundaje Anshul, Stanford University

``Learning Important Features Through Propagating Activation Differences''

Summary: Proposal to compute the saliency or attribution map using the difference between initial image (baseline) and the final map. Previous methods based on gradients are criticized as contributions with null gradient are ignored. The method described in this paper is branded as DeepLIFT (Deep Learning Important FeaTures).


\textbf{\cite{Ancona2018}:}
Ancona Marco, Enea Ceolini, Cengiz Öztireli, Markus Gross, ETH Zurich, presented at ICLR 2018
``Towards better understanding of gradient based attribution methods for deep neural networks''
Summary: Synthesis and critic of previous saliency or attribution map methods from \cite{Simonyan2014},
\cite{Sundararajan2017}, \cite{Shrikumar2017}. Aiming at providing a framework for evaluation of the different methods.


\textbf{\cite{Szegedy2014}:}

Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob

``Intriguing properties of neural networks''\\
Summary: adversarial examples; introduces the concept of adversarial examples in neural networks; shows the generalisation of such examples, which produce adversarial classification in different networks.


\textbf{\cite{Goodfellow2014}:}

Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian

``Explaining and harnessing adversarial examples''\\
Summary: adversarial examples; shows that the primary cause of adversarial classification is the linear nature of neural networs, and that this linearity can be easily exploited to generate adversarial examples.


\textbf{\cite{Su2019}:}

Su, Jiawei and Vargas, Danilo Vasconcellos and Sakurai, Kouichi

``One Pixel Attack for Fooling Deep Neural Networks''\\
Summary: altering a single pixel in an image can be enough to produce an adversarial example.


\textbf{\cite{Ilyas2019}:}

Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander

``Adversarial Examples Are Not Bugs, They Are Features''\\
Summary: adversarial examples result from non-robust features, that is, features that look incomprehensible to humans, yet, have high predictive power.


\textbf{\cite{Gu2014}:}

Gu, Shixiang and Rigazio, Luca

``Towards Deep Neural Network Architectures Robust to Adversarial Examples''\\
Summary: adversarial examples; proposes to use denoising autoencoders to remove most of the adversarial noise in training examples.


\textbf{\cite{Biggio2013}:}

Biggio, Battista and Corona, Igino and Maiorca, Davide and Nelson, Blaine and Šrndić, Nedim and Laskov, Pavel and Giacinto, Giorgio and Roli, Fabio

``Evasion Attacks against Machine Learning at Test Time''\\
Summary: adversarial examples; introduces the concept of adversarial examples in neural networks.


\textbf{\cite{Schmidt2018}:}

Schmidt, Ludwig and Santurkar, Shibani and Tsipras, Dimitris and Talwar, Kunal and Mądry, Aleksander

``Adversarially Robust Generalization Requires More Data''\\
Summary: adversarial examples; suggests that robustness results of complex interactions between the classifier model and the distribution of the data.


\textbf{\cite{Bubeck2018}:}

Schmidt, Ludwig and Santurkar, Shibani and Tsipras, Dimitris and Talwar, Kunal and Mądry, Aleksander

``Adversarial examples from computational constraints''\\
Summary: adversarial examples; adversarial examples result from unavoidable computational limitations of learning algorithms.


\textbf{\cite{Gilmer2018}:}

Gilmer, Justin and Metz, Luke and Faghri, Fartash and Schoenholz, Samuel S. and Raghu, Maithra and Wattenberg, Martin and Goodfellow, Ian

``Adversarial Spheres''\\
Summary: adversarial examples; adversarial examples result from high dimensionality of the data manifold.


\textbf{\cite{Gilmer2018}:}

Gilmer, Justin and Metz, Luke and Faghri, Fartash and Schoenholz, Samuel S. and Raghu, Maithra and Wattenberg, Martin and Goodfellow, Ian

``Adversarial Spheres''\\
Summary: adversarial examples; adversarial examples result from high dimensionality of the data manifold.


\textbf{\cite{Shafahi2018}:}

Shafahi, Ali and Huang, W. Ronny and Studer, Christoph and Feizi, Soheil and Goldstein, Tom

``Are adversarial examples inevitable?''\\
Summary: adversarial examples; adversarial examples result from dimensionality and complexity of the data.


\textbf{\cite{Tanay2016}:}

Tanay, Thomas and Griffin, Lewis

``A Boundary Tilting Persepective on the Phenomenon of Adversarial Examples''\\
Summary: adversarial examples can be largely avoided by using proper regularisation.

\textbf{\cite{Simonyan2014}:}

Karen Simonyan, Andrea Vedaldi and Andrew Zisserman

``Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps''\\
Summary: Visualise the image of classification models (saliency maps).

\textbf{\cite{Sundararajan2017}:}

Mukund Sundararajan, Ankur Taly, Qiqi Yan

``Axiomatic Attribution for Deep Networks''\\
Summary: Define awioms to guide the design of a new attribution method.

\textbf{\cite{Insitu-CNN-visualization}:}

Xinyu Chen, Qiang Guan, Li-Ta Lo, Simon Su, James Ahrens and Trilce Estrada

``In situ TensorView: In situ Visualization of
Convolutional Neural Networks''\\
Summary: Expose several visualisation technics particulary gradient based-methods.



Note: This section is primarily for our own use. Pavlo does not want it in the report. All what is needed then is to comment it in the main file to remove it.









